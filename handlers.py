# handlers.py
import logging
import ast
import io
import re
import json
import asyncio
from collections import deque
from telegram import Update
from telegram.constants import ParseMode, ChatAction
from telegram.ext import ContextTypes

# å¾æˆ‘å€‘è‡ªå·±çš„æ¨¡çµ„ä¸­åŒ¯å…¥éœ€è¦çš„æ±è¥¿
from config import (DEFAULT_MODEL, DEFAULT_PERSONA, IMAGE_SIZE_LIMIT, 
                    MAX_ROUNDS, PHOTO_PROMPT, STICKER_PROMPT, WEATHER_CITY)
from utils import (ask_ollama_once, ask_ollama_stream, stream_and_edit_message, 
                   reply_safely, image_to_base64, extract_json_from_text, filter_stream)
from tools import TOOL_REGISTRY, Tools

# --- ä¸»è¦å°è©±è™•ç† ---
async def chat(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """
    è™•ç†æ–‡å­—è¨Šæ¯ï¼Œå¯¦ç¾å‡½å¼å‘¼å«ï¼Œä¸¦ä»¥ä¸²æµæ–¹å¼å›è¦† (V10 å®Œæ•´ç‰ˆ)
    """
    user_msg = update.message.text
    user_id = update.effective_user.id
    logging.info(f"æ”¶åˆ°ä½¿ç”¨è€… {user_id} çš„è¨Šæ¯ï¼š{user_msg[:80]}...")
    await ctx.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    hist = ctx.user_data.setdefault("history", deque(maxlen=MAX_ROUNDS))
    persona = ctx.user_data.get("persona", DEFAULT_PERSONA)
    first_step_msgs = [{"role": "system", "content": persona}] + list(hist) + [{"role": "user", "content": user_msg}]
    
    # --- æ­¥é©Ÿä¸€ï¼šä½¿ç”¨éä¸²æµæ¨¡å¼é€²è¡Œå·¥å…·åˆ¤æ–· ---
    model_response = await ask_ollama_once(ctx, first_step_msgs)
    logging.info(f"æ¨¡å‹åˆæ­¥å›æ‡‰åŸæ–‡: {model_response}")

    json_str = extract_json_from_text(model_response)
    tool_calls = []
    
    if json_str:
        try:
            # ä½¿ç”¨ ast.literal_eval ä¾†è™•ç†å–®å¼•è™Ÿå’Œé›™å¼•è™Ÿçš„ JSON/Python Dict
            parsed_response = ast.literal_eval(json_str)
            if isinstance(parsed_response, list):
                tool_calls = parsed_response
            elif isinstance(parsed_response, dict):
                tool_calls.append(parsed_response)
        except Exception as e:
            logging.error(f"æœ€çµ‚è§£æå¤±æ•— ({e})ï¼Œæ”¾æ£„å·¥å…·å‘¼å«ã€‚")

    final_reply = ""
    if isinstance(tool_calls, list) and tool_calls and all(isinstance(call, dict) and "tool_name" in call for call in tool_calls):
        # --- æ­¥é©ŸäºŒï¼šåŸ·è¡Œæ‰€æœ‰è¢«è«‹æ±‚çš„å·¥å…· ---
        tool_results = []
        tasks_to_run = []
        async_calls_map = [] 

        for call in tool_calls:
            tool_name = call.get("tool_name")
            if tool_name not in TOOL_REGISTRY:
                logging.warning(f"æ¨¡å‹è«‹æ±‚äº†æœªè¨»å†Šçš„å·¥å…·: {tool_name}")
                continue

            logging.info(f"æ¨¡å‹è«‹æ±‚ä½¿ç”¨å·¥å…·: {tool_name}, åƒæ•¸: {call.get('arguments', {})}")
            tool_function = TOOL_REGISTRY[tool_name]
            arguments = call.get("arguments", {})
            
            kwargs = arguments.copy()
            if asyncio.iscoroutinefunction(tool_function):
                if tool_name == 'get_current_weather': 
                    kwargs['session'] = ctx.bot_data['aiohttp_session']
                    kwargs.setdefault('city', WEATHER_CITY)
                tasks_to_run.append(tool_function(**kwargs))
                async_calls_map.append(call)
            else:
                if tool_name in ['add_todo', 'list_todos']: 
                    kwargs['ctx'] = ctx
                result = tool_function(**kwargs)
                tool_results.append({"tool_call": call, "result": result})

        if tasks_to_run:
            async_results = await asyncio.gather(*tasks_to_run)
            for call, result in zip(async_calls_map, async_results):
                tool_results.append({"tool_call": call, "result": result})

        # --- æ­¥é©Ÿä¸‰ï¼šä½¿ç”¨ä¸²æµæ¨¡å¼ç”Ÿæˆæœ€çµ‚å›è¦† ---
        second_step_msgs = first_step_msgs
        for res in tool_results:
            logging.info(f"å·¥å…· {res['tool_call'].get('tool_name')} åŸ·è¡Œçµæœ: {str(res['result'])[:150]}...")
            second_step_msgs.extend([
                {"role": "assistant", "content": json.dumps(res['tool_call'], ensure_ascii=False)},
                {"role": "tool", "content": str(res['result'])}
            ])
        # --- âœ¨ æ­¥é©Ÿä¸‰ï¼šä½¿ç”¨ä¸²æµæ¨¡å¼ç”Ÿæˆæœ€çµ‚å›è¦† (åŠ å…¥éæ¿¾) ---
        raw_generator = ask_ollama_stream(ctx, second_step_msgs)
        # å°‡åŸå§‹ç”¢ç”Ÿå™¨ç”¨ filter_stream åŒ…è£èµ·ä¾†
        filtered_generator = filter_stream(raw_generator) 
        final_reply = await stream_and_edit_message(update, ctx, filtered_generator)
    else:
        # --- ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥ä»¥ä¸²æµæ¨¡å¼å›è¦† ---
        # å› ç‚º model_response æ˜¯å®Œæ•´çš„ï¼Œæˆ‘å€‘è¦æŠŠå®ƒè®Šæˆä¸€å€‹å‡çš„éåŒæ­¥ç”¢ç”Ÿå™¨
        cleaned_response = re.sub(r'<think>.*?</think>\s*', '', model_response, flags=re.DOTALL).strip()
        
        async def text_generator(text):
            # æ¨¡æ“¬ä¸²æµï¼Œå°‡æ–‡å­—åˆ†å¡Šç”¢å‡º
            for i in range(0, len(text), 10): # æ¯ 10 å€‹å­—å…ƒç‚ºä¸€å¡Š
                yield text[i:i+10]
                await asyncio.sleep(0.01) # æ¨¡æ“¬ç¶²è·¯å»¶é²ï¼Œè®“æ‰“å­—æ•ˆæœæ›´æ˜é¡¯
        
        response_generator = text_generator(cleaned_response)
        final_reply = await stream_and_edit_message(update, ctx, response_generator)
    
    # å°‡æœ€çµ‚çš„å®Œæ•´å›è¦†å­˜å…¥æ­·å²
    #cleaned_reply = re.sub(r'<think>.*?</think>\s*', '', final_reply, flags=re.DOTALL).strip()
    cleaned_reply = final_reply 
    if not cleaned_reply:
        cleaned_reply = "ï¼ˆæˆ‘å¥½åƒæœ‰é»ä¸çŸ¥é“è©²èªªä»€éº¼äº†...ï¼‰"
    
    hist.append({"role": "user", "content": user_msg})
    hist.append({"role": "assistant", "content": cleaned_reply})

# --- åœ–ç‰‡/è²¼åœ–è™•ç† ---
async def photo_or_sticker_handler(update: Update, ctx: ContextTypes.DEFAULT_TYPE, is_sticker: bool):
    file_id, file_size = (None, None)
    if is_sticker:
        sticker = update.message.sticker
        if sticker.is_animated or sticker.is_video: await update.message.reply_text("æŠ±æ­‰ï¼Œæˆ‘ä¸æ”¯æ´å‹•æ…‹æˆ–å½±ç‰‡è²¼åœ–å–”ï½"); return
        file_id, file_size = sticker.file_id, sticker.file_size
    else:
        photo = update.message.photo[-1]
        file_id, file_size = photo.file_id, photo.file_size
    
    if file_size and file_size > IMAGE_SIZE_LIMIT: await update.message.reply_text(f"âš ï¸ æª”æ¡ˆéå¤§"); return
    await ctx.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    try:
        tg_file = await ctx.bot.get_file(file_id)
        with io.BytesIO() as bio:
            await tg_file.download_to_memory(out=bio); bio.seek(0)
            image_b64 = image_to_base64(bio.getvalue())
        
        hist = ctx.user_data.setdefault("history", deque(maxlen=MAX_ROUNDS))
        persona = ctx.user_data.get("persona", DEFAULT_PERSONA)
        prompt = STICKER_PROMPT if is_sticker else PHOTO_PROMPT
        user_msg_for_hist = "(å‚³é€äº†ä¸€å¼µè²¼åœ–)" if is_sticker else "(å‚³é€äº†ä¸€å¼µç…§ç‰‡)"
        
        msgs = [{"role": "system", "content": persona}] + list(hist) + [{"role": "user", "content": prompt}]
        reply = await ask_ollama_once(ctx, msgs, image_b64=image_b64)
        cleaned_reply = re.sub(r'<think>.*?</think>\s*', '', reply, flags=re.DOTALL).strip()
        
        hist.append({"role": "user", "content": user_msg_for_hist})
        hist.append({"role": "assistant", "content": cleaned_reply})
        await reply_safely(update, cleaned_reply)
    except Exception as e:
        logging.error(f"è™•ç†åœ–ç‰‡/è²¼åœ–æ™‚å‡ºéŒ¯: {e}"); await update.message.reply_text("âš ï¸ è™•ç†åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚")

async def photo_handler(update: Update, ctx: ContextTypes.DEFAULT_TYPE): await photo_or_sticker_handler(update, ctx, is_sticker=False)
async def sticker_handler(update: Update, ctx: ContextTypes.DEFAULT_TYPE): await photo_or_sticker_handler(update, ctx, is_sticker=True)


# --- æŒ‡ä»¤è™•ç† ---
async def start(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_name = update.effective_user.first_name
    welcome_message = (f"å“ˆå›‰ï¼Œ{user_name}ï½ ä½ å¥½å‘€ï¼ğŸ–ï¸\næˆ‘æ˜¯ä½ çš„ç§äººåŠ©æ‰‹ Lala ï¼šï¼‰\n\n"
                     "ä½ å¯ä»¥éš¨æ™‚é–‹å§‹è·Ÿæˆ‘èŠå¤©ã€å‚³ç…§ç‰‡æˆ–è²¼åœ–ï¼Œæˆ–è€…è¦æˆ‘å¹«ä½ æŸ¥å¤©æ°£ã€æ‰¾è³‡æ–™ã€çœ‹æ–°èéƒ½å¯ä»¥å–”ï¼\n\n"
                     "å¦‚æœéœ€è¦é‡è¨­æˆ‘å€‘çš„å°è©±ï¼Œå¯ä»¥è¼¸å…¥ `/reset`ã€‚")
    await update.message.reply_text(welcome_message)

class BotCommands:
    @staticmethod
    async def set_model(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
        if not ctx.args:
            current_model = ctx.user_data.get("model", DEFAULT_MODEL)
            await update.message.reply_text(f"ç›®å‰æ¨¡å‹ï¼š`{current_model}`\nç”¨æ³•ï¼š`/model llama3:8b`", parse_mode=ParseMode.MARKDOWN)
            return
        model_name = ctx.args[0]
        ctx.user_data["model"] = model_name
        await update.message.reply_text(f"âœ… æ¨¡å‹å·²åˆ‡æ›ç‚º `{model_name}`", parse_mode=ParseMode.MARKDOWN)
    
    @staticmethod
    async def reset(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
        ctx.user_data.clear()
        await update.message.reply_text("ğŸ—‘ï¸ å·²æ¸…ç©ºæ‚¨çš„å€‹äººå°è©±æ­·å²ã€æ¨¡å‹å’Œ persona è¨­å®šã€‚")

    # ... æ‚¨å¯ä»¥å°‡ list_models å’Œ set_persona ä¹Ÿæ”¾åœ¨é€™è£¡ ...