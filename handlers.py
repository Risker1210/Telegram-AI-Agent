# handlers.py
import logging
import ast
import io
import re
import json
import asyncio
from collections import deque
from telegram import Update
from telegram.constants import ParseMode, ChatAction
from telegram.ext import ContextTypes

# å¾æˆ‘å€‘è‡ªå·±çš„æ¨¡çµ„ä¸­åŒ¯å…¥éœ€è¦çš„æ±è¥¿
from config import *
from utils import (ask_ollama_once, ask_ollama_stream, stream_and_edit_message, 
                   reply_safely, image_to_base64, extract_json_from_text, filter_stream)
from tools import TOOL_REGISTRY, Tools

# --- ä¸»è¦å°è©±è™•ç† ---
async def chat(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """
    è™•ç†æ–‡å­—è¨Šæ¯çš„æœ€çµ‚ç‰ˆ ReAct å¾ªç’°ï¼Œæ¡ç”¨ç°¡åŒ–çš„å·¥å…·ç®±å’Œå¼·åŒ–çš„å·¥ä½œæµã€‚
    """
    user_msg = update.message.text
    user_id = update.effective_user.id
    logging.info(f"æ”¶åˆ°ä½¿ç”¨è€… {user_id} çš„è¨Šæ¯ï¼š{user_msg[:80]}...")
    await ctx.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    # æº–å‚™å°è©±æ­·å²èˆ‡ Persona
    hist = ctx.user_data.setdefault("history", deque(maxlen=MAX_ROUNDS))
    persona = ctx.user_data.get("persona", DEFAULT_PERSONA)
    first_step_msgs = [{"role": "system", "content": persona}] + list(hist) + [{"role": "user", "content": user_msg}]
    
    # æ­¥é©Ÿä¸€ï¼šå‘¼å«æ¨¡å‹ï¼Œç²å–åˆæ­¥å›æ‡‰
    model_response = await ask_ollama_once(ctx, first_step_msgs)
    logging.info(f"æ¨¡å‹åˆæ­¥å›æ‡‰åŸæ–‡: {model_response}")

    # æ­¥é©ŸäºŒï¼šå¾å›æ‡‰ä¸­æå–ä¸¦è§£æå·¥å…·è«‹æ±‚
    json_str = extract_json_from_text(model_response)
    tool_calls = []
    if json_str:
        try:
            parsed_response = ast.literal_eval(json_str.replace("'", '"'))
            if isinstance(parsed_response, list):
                tool_calls = parsed_response
            elif isinstance(parsed_response, dict):
                tool_calls.append(parsed_response)
        except Exception as e:
            logging.error(f"æœ€çµ‚è§£æå¤±æ•— ({e})ï¼Œæ”¾æ£„å·¥å…·å‘¼å«ã€‚")

    final_reply = ""
    
    # æ­¥é©Ÿä¸‰ï¼šæ ¸å¿ƒæ±ºç­– -> æ ¹æ“šæœ‰ç„¡å·¥å…·è«‹æ±‚ï¼Œé€²å…¥ä¸åŒåˆ†æ”¯
    if isinstance(tool_calls, list) and tool_calls and all(isinstance(call, dict) and "tool_name" in call for call in tool_calls):
        
        logging.info(f"åµæ¸¬åˆ°æœ‰æ•ˆå·¥å…·è«‹æ±‚: {[call.get('tool_name') for call in tool_calls]}")
        
        # --- âœ¨ V20 æ ¸å¿ƒæ”¹å‹•ï¼šä¸å†æœ‰ is_briefing_task çš„ç‰¹æ®Šåˆ¤æ–· ---
        # --- æ‰€æœ‰å·¥å…·éƒ½èµ°æ¨™æº–çš„ ReAct å¾ªç’° ---
        
        tool_results, tasks_to_run, async_calls_map = [], [], []
        for call in tool_calls:
            tool_name = call.get("tool_name")
            if tool_name not in TOOL_REGISTRY:
                logging.warning(f"è«‹æ±‚äº†æœªè¨»å†Šçš„å·¥å…·: {tool_name}")
                continue

            logging.info(f"åŸ·è¡Œå·¥å…·: {tool_name}, åƒæ•¸: {call.get('arguments', {})}")
            tool_function = TOOL_REGISTRY[tool_name]
            arguments = call.get("arguments", {})
            kwargs = arguments.copy()

            if asyncio.iscoroutinefunction(tool_function):
                if tool_name == 'get_current_weather': 
                    kwargs['ctx'] = ctx
                    kwargs.setdefault('city', WEATHER_CITY)
                tasks_to_run.append(tool_function(**kwargs))
                async_calls_map.append(call)
            else:
                if tool_name in ['add_todo', 'list_todos', 'get_news_headlines']: 
                    kwargs['ctx'] = ctx
                result = tool_function(**kwargs)
                tool_results.append({"tool_call": call, "result": result})

        if tasks_to_run:
            async_results = await asyncio.gather(*tasks_to_run)
            for call, result in zip(async_calls_map, async_results):
                tool_results.append({"tool_call": call, "result": result})

        second_step_msgs = first_step_msgs
        for res in tool_results:
            tool_name = res['tool_call'].get('tool_name')
            tool_result_str = str(res['result'])
            logging.info(f"å·¥å…· {tool_name} åŸ·è¡Œçµæœ: {tool_result_str[:150]}...")
            
            # âœ¨ V20 æ ¸å¿ƒæ”¹å‹•ï¼šç‚ºæ–°èå·¥å…·å»ºç«‹å°ˆå±¬çš„ã€Œæœ€çµ‚çƒ¹é£ªæŒ‡ä»¤ã€
            final_instruction = ""
            if tool_name == 'get_news_headlines':
                final_instruction = (
                    "å·¥å…·ã€Œget_news_headlinesã€å·²ç¶“åŸ·è¡Œå®Œæˆï¼Œä»¥ä¸‹æ˜¯å®ƒå›å‚³çš„åŸå§‹æ–°èæ–‡ç« åˆ—è¡¨ï¼ˆJSON æ ¼å¼ï¼‰ã€‚\n"
                    "è«‹ä½ æ‰®æ¼”ä¸€ä½å°ˆæ¥­åˆæœ‰è¶£çš„æ–°èä¸»æ’­ï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š\n"
                    "1. é–±è®€æ‰€æœ‰æ–‡ç« ï¼Œç¯©é¸å‡º 2-3 å‰‡æœ€é‡è¦æˆ–æœ€æœ‰è¶£çš„æ–°èã€‚\n"
                    "2. ç‚ºæ¯ä¸€å‰‡é¸å‡ºçš„æ–°èï¼Œå¯«ä¸€æ®µç²¾ç°¡åˆæœ‰å¸å¼•åŠ›çš„æ‘˜è¦ã€‚\n"
                    "3. æŒ‰ç…§é‡è¦æ€§æ’åºï¼Œå°‡æ‘˜è¦æ•´ç†æˆä¸€ä»½æ–°èç°¡å ±ã€‚\n"
                    "4. æœ€å¾Œï¼Œä»¥ Lala çš„å£å»å ±å°é€™ä»½ç°¡å ±ï¼Œä¸¦å‹™å¿…åœ¨æ¯å‰‡æ–°èçš„çµå°¾é™„ä¸ŠåŸå§‹çš„ `url` é€£çµã€‚\n\n"
                    f"ã€åŸå§‹æ–°èæ•¸æ“šã€‘\n---\n{tool_result_str}\n---"
                )
            else:
                # å°æ–¼å…¶ä»–å·¥å…·ï¼Œä½¿ç”¨æˆ‘å€‘ä¹‹å‰è¨­è¨ˆçš„é€šç”¨æŒ‡ä»¤
                final_instruction = (
                    f"å·¥å…·ã€Œ{tool_name}ã€å·²ç¶“åŸ·è¡Œå®Œæˆï¼Œä»¥ä¸‹æ˜¯å®ƒçš„åŸå§‹å›å‚³æ•¸æ“šã€‚\n"
                    "è«‹ä½ **å‹™å¿…**åŸºæ–¼é€™äº›æ•¸æ“šï¼Œè€Œä¸æ˜¯ä½ è‡ªå·±çš„å…§éƒ¨çŸ¥è­˜ï¼Œ"
                    "ä»¥ Lala çš„å£å»å’Œé¢¨æ ¼ï¼Œç”Ÿæˆä¸€æ®µè‡ªç„¶çš„ã€å£èªåŒ–çš„ã€å®Œæ•´çš„å°è©±ä¾†å›è¦†ä½¿ç”¨è€…ã€‚\n\n"
                    f"ã€å·¥å…·æ•¸æ“šã€‘\n---\n{tool_result_str}\n---"
                )

            second_step_msgs.extend([
                {"role": "assistant", "content": json.dumps(res['tool_call'], ensure_ascii=False)},
                {"role": "tool", "content": final_instruction}
            ])
        
        raw_generator = ask_ollama_stream(ctx, second_step_msgs)
        filtered_generator = filter_stream(raw_generator)
        final_reply = await stream_and_edit_message(update, ctx, filtered_generator)

    else:
        # --- åˆ†æ”¯ Cï¼šæ™®é€šèŠå¤© ---
        logging.info("æœªåµæ¸¬åˆ°æœ‰æ•ˆå·¥å…·è«‹æ±‚ï¼Œç•¶ä½œä¸€èˆ¬å°è©±è™•ç†ã€‚")
        async def text_generator(text):
            cleaned_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
            for i in range(0, len(cleaned_text), 10):
                yield cleaned_text[i:i+10]
                await asyncio.sleep(0.01)
        
        response_generator = text_generator(model_response)
        final_reply = await stream_and_edit_message(update, ctx, response_generator)
    
    # --- æ­¥é©Ÿå››ï¼šå„²å­˜æœ€çµ‚æ­·å²ç´€éŒ„ ---
    if not final_reply: 
        final_reply = "ï¼ˆæˆ‘å¥½åƒæœ‰é»ä¸çŸ¥é“è©²èªªä»€éº¼äº†...ï¼‰"
    
    hist.append({"role": "user", "content": user_msg})
    hist.append({"role": "assistant", "content": final_reply})

# --- åœ–ç‰‡/è²¼åœ–è™•ç† ---
async def photo_or_sticker_handler(update: Update, ctx: ContextTypes.DEFAULT_TYPE, is_sticker: bool):
    file_id, file_size = (None, None)
    if is_sticker:
        sticker = update.message.sticker
        if sticker.is_animated or sticker.is_video: await update.message.reply_text("æŠ±æ­‰ï¼Œæˆ‘ä¸æ”¯æ´å‹•æ…‹æˆ–å½±ç‰‡è²¼åœ–å–”ï½"); return
        file_id, file_size = sticker.file_id, sticker.file_size
    else:
        photo = update.message.photo[-1]
        file_id, file_size = photo.file_id, photo.file_size
    
    if file_size and file_size > settings.IMAGE_SIZE_LIMIT: await update.message.reply_text(f"âš ï¸ æª”æ¡ˆéå¤§"); return
    await ctx.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    try:
        tg_file = await ctx.bot.get_file(file_id)
        with io.BytesIO() as bio:
            await tg_file.download_to_memory(out=bio); bio.seek(0)
            image_b64 = image_to_base64(bio.getvalue())
        
        hist = ctx.user_data.setdefault("history", deque(maxlen=settings.MAX_ROUNDS))
        persona = ctx.user_data.get("persona", settings.DEFAULT_PERSONA)
        prompt = settings.STICKER_PROMPT if is_sticker else settings.PHOTO_PROMPT
        user_msg_for_hist = "(å‚³é€äº†ä¸€å¼µè²¼åœ–)" if is_sticker else "(å‚³é€äº†ä¸€å¼µç…§ç‰‡)"
        
        msgs = [{"role": "system", "content": persona}] + list(hist) + [{"role": "user", "content": prompt}]
        reply = await ask_ollama_once(ctx, msgs, image_b64=image_b64)
        cleaned_reply = re.sub(r'<think>.*?</think>\s*', '', reply, flags=re.DOTALL).strip()
        
        hist.append({"role": "user", "content": user_msg_for_hist})
        hist.append({"role": "assistant", "content": cleaned_reply})
        await reply_safely(update, cleaned_reply)
    except Exception as e:
        logging.error(f"è™•ç†åœ–ç‰‡/è²¼åœ–æ™‚å‡ºéŒ¯: {e}"); await update.message.reply_text("âš ï¸ è™•ç†åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚")

async def photo_handler(update: Update, ctx: ContextTypes.DEFAULT_TYPE): await photo_or_sticker_handler(update, ctx, is_sticker=False)
async def sticker_handler(update: Update, ctx: ContextTypes.DEFAULT_TYPE): await photo_or_sticker_handler(update, ctx, is_sticker=True)


# --- æŒ‡ä»¤è™•ç† ---
async def start(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_name = update.effective_user.first_name
    welcome_message = (f"å“ˆå›‰ï¼Œ{user_name}ï½ ä½ å¥½å‘€ï¼ğŸ–ï¸\næˆ‘æ˜¯ä½ çš„ç§äººåŠ©æ‰‹ Lala ï¼šï¼‰\n\n"
                     "ä½ å¯ä»¥éš¨æ™‚é–‹å§‹è·Ÿæˆ‘èŠå¤©ã€å‚³ç…§ç‰‡æˆ–è²¼åœ–ï¼Œæˆ–è€…è¦æˆ‘å¹«ä½ æŸ¥å¤©æ°£ã€æ‰¾è³‡æ–™ã€çœ‹æ–°èéƒ½å¯ä»¥å–”ï¼\n\n"
                     "å¦‚æœéœ€è¦é‡è¨­æˆ‘å€‘çš„å°è©±ï¼Œå¯ä»¥è¼¸å…¥ `/reset`ã€‚")
    await update.message.reply_text(welcome_message)

class BotCommands:
    @staticmethod
    async def set_model(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
        if not ctx.args:
            current_model = ctx.user_data.get("model", settings.DEFAULT_MODEL)
            await update.message.reply_text(f"ç›®å‰æ¨¡å‹ï¼š`{current_model}`\nç”¨æ³•ï¼š`/model llama3:8b`", parse_mode=ParseMode.MARKDOWN)
            return
        model_name = ctx.args[0]
        ctx.user_data["model"] = model_name
        await update.message.reply_text(f"âœ… æ¨¡å‹å·²åˆ‡æ›ç‚º `{model_name}`", parse_mode=ParseMode.MARKDOWN)
    
    @staticmethod
    async def reset(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
        ctx.user_data.clear()
        await update.message.reply_text("ğŸ—‘ï¸ å·²æ¸…ç©ºæ‚¨çš„å€‹äººå°è©±æ­·å²ã€æ¨¡å‹å’Œ persona è¨­å®šã€‚")

    # ... æ‚¨å¯ä»¥å°‡ list_models å’Œ set_persona ä¹Ÿæ”¾åœ¨é€™è£¡ ...